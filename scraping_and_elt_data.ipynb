{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- country (ctry), \n",
    "- lower layer super output area (lsoa), \n",
    "- local authority (ltla), \n",
    "- middle layer super output area (msoa), \n",
    "- output area (oa), \n",
    "- region (rgn), \n",
    "- upper tier local authority (utla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_download_links(url):\n",
    "    \"\"\"\n",
    "    Function to scrape the web page to find direct download links for zip files.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Base URL for constructing the full URL\n",
    "    base_url = 'https://www.nomisweb.co.uk'\n",
    "\n",
    "    # Find all <a> tags with href attribute containing the zip file path\n",
    "    download_links = soup.find_all('a', href=lambda href: href and '.zip' in href)\n",
    "\n",
    "    # Construct full URLs\n",
    "    full_urls = [base_url + link['href'] for link in download_links]\n",
    "\n",
    "    # Filter and return URLs that match the expected format\n",
    "    return [url for url in full_urls if url.startswith('https://www.nomisweb.co.uk/output/census/2021/')]\n",
    "\n",
    "\n",
    "def download_and_extract_zip(url, extract_to_folder):\n",
    "    \"\"\"\n",
    "    function to download, extract only CSV files containing 'oa' or 'lsoa' in their names from a given zip file URL, \n",
    "    and delete the zip file, whether it's empty or not, after attempting extraction.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    zip_filename = os.path.join(extract_to_folder, url.split('/')[-1])\n",
    "    \n",
    "    with open(zip_filename, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "            # Check if the zip file is empty\n",
    "            if len(zip_ref.namelist()) == 0:\n",
    "                raise ValueError(f\"Zip file {zip_filename} is empty and can't be extracted.\")\n",
    "\n",
    "            # List all file names in the zip file\n",
    "            all_files = zip_ref.namelist()\n",
    "\n",
    "            # Filter out files that are not CSV or don't contain 'oa' or 'lsoa' in their names\n",
    "            filtered_files = [f for f in all_files if f.endswith('.csv') and ('-oa' in f.lower() or '-lsoa' in f.lower())]\n",
    "\n",
    "            # Extract only the filtered files\n",
    "            for file in filtered_files:\n",
    "                zip_ref.extract(file, extract_to_folder)\n",
    "    finally:\n",
    "        # Delete the zip file after extraction or if it's empty\n",
    "        os.remove(zip_filename)\n",
    "\n",
    "def download_and_extract_shapefiles(url, extract_to_folder):\n",
    "    \"\"\"\n",
    "    Download a zip file from the URL and extract its contents to the specified folder.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the file name from the URL\n",
    "        zip_filename = os.path.join(extract_to_folder, url.split('/')[-1])\n",
    "\n",
    "        # Download the zip file\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # will raise an exception for HTTP error codes\n",
    "\n",
    "        # Write the downloaded content to a file\n",
    "        with open(zip_filename, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "\n",
    "        # Extract the zip file\n",
    "        with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_to_folder)\n",
    "\n",
    "        print(f\"Extracted {zip_filename} to {extract_to_folder}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    finally:\n",
    "        # Delete the zip file after extraction\n",
    "        if os.path.exists(zip_filename):\n",
    "            os.remove(zip_filename)\n",
    "            print(f\"Deleted {zip_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading or extracting https://www.nomisweb.co.uk/output/census/2021/census2021-ts079.zip: File is not a zip file\n",
      "Error downloading or extracting https://www.nomisweb.co.uk/output/census/2021/census2021-ts079-extra.zip: File is not a zip file\n",
      "Error downloading or extracting https://www.nomisweb.co.uk/output/census/2021/census2021-ts070-extra.zip: File is not a zip file\n",
      "Error downloading or extracting https://www.nomisweb.co.uk/output/census/2021/census2021-ts077-extra.zip: File is not a zip file\n",
      "Error downloading or extracting https://www.nomisweb.co.uk/output/census/2021/census2021-ts078-extra.zip: File is not a zip file\n",
      "Error downloading or extracting https://www.nomisweb.co.uk/output/census/2021/census2021-ts037asp-extra.zip: File is not a zip file\n",
      "Error downloading or extracting https://www.nomisweb.co.uk/output/census/2021/census2021-ts038asp-extra.zip: File is not a zip file\n",
      "Error downloading or extracting https://www.nomisweb.co.uk/output/census/2021/census2021-ts039asp-extra.zip: File is not a zip file\n",
      "Download and extraction completed.\n"
     ]
    }
   ],
   "source": [
    "# URL of the page to scrape\n",
    "scrape_url = 'https://www.nomisweb.co.uk/sources/census_2021_bulk'\n",
    "\n",
    "# Directory for downloads and extractions\n",
    "extract_to_folder = os.path.join(os.getcwd(), \"data\")\n",
    "os.makedirs(extract_to_folder, exist_ok=True)\n",
    "\n",
    "# Get all download links\n",
    "try:\n",
    "    zip_file_urls = find_download_links(scrape_url)\n",
    "\n",
    "    # Download and extract each zip file\n",
    "    for url in zip_file_urls:\n",
    "        try:\n",
    "            download_and_extract_zip(url, extract_to_folder)\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading or extracting {url}: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error scraping {scrape_url}: {e}\")\n",
    "\n",
    "print(\"Download and extraction completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of shape file\n",
    "shapes_url = 'https://data.london.gov.uk/download/statistical-gis-boundary-files-london/9ba8c833-6370-4b11-abdc-314aa020d5e0/statistical-gis-boundaries-london.zip'\n",
    "try:\n",
    "    download_and_extract_shapefiles(shapes_url, extract_to_folder)\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading or extracting {shapes_url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The file census2021-ts010-oa.csv is empty and will be skipped.\n",
      "Warning: The file census2021-ts010-lsoa.csv is empty and will be skipped.\n"
     ]
    }
   ],
   "source": [
    "def merge_csv_files(directory, file_suffix):\n",
    "    \"\"\"\n",
    "    Merge all CSV files in the directory that end with a specific suffix.\n",
    "    Use 'date' and 'geography code' for merging, and include all columns from all files.\n",
    "    Skip over any files that are empty.\n",
    "    \"\"\"\n",
    "    merged_df = None\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(file_suffix + '.csv'):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            try:\n",
    "                df = pd.read_csv(filepath)\n",
    "                df.drop(columns=['geography'], inplace=True, errors='ignore')\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: The file {filename} is empty and will be skipped.\")\n",
    "                continue\n",
    "\n",
    "            if merged_df is None:\n",
    "                merged_df = df\n",
    "            else:\n",
    "                merged_df = pd.merge(merged_df, df, on=['date', 'geography code'], how='outer')\n",
    "\n",
    "    # Check for duplicates and remove them\n",
    "    if merged_df is not None and merged_df.duplicated().any():\n",
    "        num_duplicates = merged_df.duplicated().sum()\n",
    "        print(f\"Number of duplicates in {file_suffix} files: {num_duplicates}\")\n",
    "        merged_df.drop_duplicates(inplace=True)\n",
    "        \n",
    "    return merged_df\n",
    "\n",
    "\n",
    "# Merge and save 'oa' files\n",
    "merged_oa_df = merge_csv_files(extract_to_folder, '-oa')\n",
    "merged_oa_df = merged_oa_df.rename(columns={'geography code':'OA11CD'})\n",
    "merged_oa_df.to_csv(os.path.join(extract_to_folder, 'combined_oa.csv'), index=False)\n",
    "\n",
    "# Merge and save 'lsoa' files\n",
    "merged_lsoa_df = merge_csv_files(extract_to_folder, 'lsoa')\n",
    "merged_lsoa_df = merged_lsoa_df.rename(columns={'geography code':'LSOA11CD'})\n",
    "merged_lsoa_df.to_csv(os.path.join(extract_to_folder, 'combined_lsoa.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Welsh language skills: Total: All usual residents aged 3 years and over' has 178605 nulls\n",
      "Column 'Welsh language skills: Can understand spoken Welsh only' has 178605 nulls\n",
      "Column 'Welsh language skills: Can speak, read and write Welsh' has 178605 nulls\n",
      "Column 'Welsh language skills: Can speak but cannot read or write Welsh' has 178605 nulls\n",
      "Column 'Welsh language skills: Can speak and read but cannot write Welsh' has 178605 nulls\n",
      "Column 'Welsh language skills: Can read but cannot speak or write Welsh' has 178605 nulls\n",
      "Column 'Welsh language skills: Can write but cannot speak or read Welsh' has 178605 nulls\n",
      "Column 'Welsh language skills: Can read and write but cannot speak Welsh' has 178605 nulls\n",
      "Column 'Welsh language skills: Can speak and other combinations of skills in Welsh' has 178605 nulls\n",
      "Column 'Welsh language skills: No skills in Welsh' has 178605 nulls\n",
      "Column 'Welsh speaking ability: Total: All usual residents aged 3 years and over' has 178605 nulls\n",
      "Column 'Welsh speaking ability: Cannot speak Welsh' has 178605 nulls\n",
      "Column 'Welsh speaking ability: Can speak Welsh' has 178605 nulls\n",
      "Column 'Welsh writing ability: Total: All usual residents aged 3 years and over' has 178605 nulls\n",
      "Column 'Welsh writing ability: Cannot write Welsh' has 178605 nulls\n",
      "Column 'Welsh writing ability: Can write Welsh' has 178605 nulls\n",
      "Column 'Welsh reading ability: Total: All usual residents aged 3 years and over' has 178605 nulls\n",
      "Column 'Welsh reading ability: Cannot read Welsh' has 178605 nulls\n",
      "Column 'Welsh reading ability: Can read Welsh' has 178605 nulls\n",
      "Column 'Welsh understanding ability: Total: All usual residents aged 3 years and over' has 178605 nulls\n",
      "Column 'Welsh understanding ability: Cannot understand spoken Welsh' has 178605 nulls\n",
      "Column 'Welsh understanding ability: Can understand spoken Welsh' has 178605 nulls\n"
     ]
    }
   ],
   "source": [
    "# Find columns with nulls and count them\n",
    "null_counts = merged_oa_df.isnull().sum()\n",
    "columns_with_nulls = null_counts[null_counts > 0]\n",
    "\n",
    "# Print columns with nulls and their counts\n",
    "for column, count in columns_with_nulls.items():\n",
    "    print(f\"Column '{column}' has {count} nulls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25053, 8), 25053, (4835, 8), 4835)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oa_shape = gpd.read_file(f\"{os.getcwd()}\\\\data\\\\statistical-gis-boundaries-london\\\\ESRI\\\\OA_2011_London_gen_MHW.shp\")\n",
    "oa_shape = oa_shape[['OA11CD','USUALRES','HHOLDRES', 'COMESTRES', 'POPDEN', 'HHOLDS', 'AVHHOLDSZ', 'geometry']]\n",
    "\n",
    "lsoa_shape = gpd.read_file(f\"{os.getcwd()}\\\\data\\\\statistical-gis-boundaries-london\\\\ESRI\\\\LSOA_2011_London_gen_MHW.shp\")\n",
    "lsoa_shape = lsoa_shape[['LSOA11CD','USUALRES', 'HHOLDRES', 'COMESTRES', 'POPDEN', 'HHOLDS', 'AVHHOLDSZ', 'geometry']]\n",
    "\n",
    "oa_shape.shape, len(oa_shape.OA11CD.unique()), lsoa_shape.shape, len(lsoa_shape.LSOA11CD.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge complete. Files saved. Merged data shape is: (23913, 497), excluded data shape is: (166107, 497)\n",
      "\n",
      "Cencus data's geocode is 164967 more than 2011 shape file's geocode.\n",
      "Merge complete. Files saved. Merged data shape is: (4659, 950), excluded data shape is: (31189, 950)\n",
      "\n",
      "Cencus data's geocode is 31013 more than 2011 shape file's geocode.\n"
     ]
    }
   ],
   "source": [
    "def merge_and_save_data(df1, df2, join_column, output_folder, merged_filename, excluded_filename):\n",
    "    \"\"\"\n",
    "    Merge two DataFrames on a specified column, save the merged result, \n",
    "    and also save the data from each DataFrame not included in the merge.\n",
    "\n",
    "    :param df1: First DataFrame.\n",
    "    :param df2: Second DataFrame.\n",
    "    :param join_column: Column name on which to join.\n",
    "    :param output_folder: Folder to save the output files.\n",
    "    :param merged_filename: Filename for the merged data.\n",
    "    :param excluded_filename: Filename for the data excluded from the merge.\n",
    "    \"\"\"\n",
    "    # inner join\n",
    "    merged_df = pd.merge(df1, df2, on=join_column, how='inner')\n",
    "    merged_df.to_csv(os.path.join(output_folder, merged_filename), index=False)\n",
    "\n",
    "    # save excluded data\n",
    "    excluded_df1 = df1[~df1[join_column].isin(merged_df[join_column])]\n",
    "    excluded_df2 = df2[~df2[join_column].isin(merged_df[join_column])]\n",
    "    excluded_df = pd.concat([excluded_df1, excluded_df2], ignore_index=True)\n",
    "    excluded_df.to_csv(os.path.join(output_folder, excluded_filename), index=False)\n",
    "\n",
    "    print(f\"Merge complete. Files saved. Merged data shape is: {merged_df.shape}, excluded data shape is: {excluded_df.shape}\")\n",
    "    print(f\"\\nCencus data's geocode is {len(set(df1[join_column].unique())-set(df2[join_column].unique()))} more than 2011 shape file's geocode.\")\n",
    "\n",
    "oa_df = merged_oa_df.drop('date', axis=1)    \n",
    "lsoa_df = merged_lsoa_df.drop('date', axis=1)\n",
    "\n",
    "# for OA data\n",
    "merge_and_save_data(\n",
    "    oa_df, \n",
    "    oa_shape, \n",
    "    'OA11CD', \n",
    "    extract_to_folder, \n",
    "    'merged_inner_oa.csv', \n",
    "    'excluded_oa_data.csv'\n",
    ")\n",
    "\n",
    "# for LSOA data\n",
    "merge_and_save_data(\n",
    "    lsoa_df, \n",
    "    lsoa_shape, \n",
    "    'LSOA11CD', \n",
    "    extract_to_folder, \n",
    "    'merged_inner_lsoa.csv', \n",
    "    'excluded_lsoa_data.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_files(folder, filenames, zip_name):\n",
    "    \"\"\"\n",
    "    Zip multiple files into a single zip archive.\n",
    "\n",
    "    :param folder: The folder where files are located.\n",
    "    :param filenames: A list of filenames to be zipped.\n",
    "    :param zip_name: The name of the output zip file.\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(os.path.join(folder, zip_name), 'w') as zipf:\n",
    "        for file in filenames:\n",
    "            file_path = os.path.join(folder, file)\n",
    "            if os.path.exists(file_path):\n",
    "                zipf.write(file_path, arcname=file)\n",
    "        print(f\"Files zipped into {zip_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files zipped into oa.zip\n",
      "Files zipped into lsoa.zip\n"
     ]
    }
   ],
   "source": [
    "extract_to_folder = os.path.join(os.getcwd(), \"data\")\n",
    "\n",
    "# Zipping OA files\n",
    "oa_files = ['merged_inner_oa.csv', 'excluded_oa_data.csv']\n",
    "zip_files(extract_to_folder, oa_files, 'oa.zip')\n",
    "\n",
    "# Zipping LSOA files\n",
    "lsoa_files = ['merged_inner_lsoa.csv', 'excluded_lsoa_data.csv']\n",
    "zip_files(extract_to_folder, lsoa_files, 'lsoa.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inconsistencies found:\n",
      "census2021-ts010-lsoa.csv: Error reading file - No columns to parse from file\n",
      "census2021-ts010-oa.csv: Error reading file - No columns to parse from file\n",
      "combined_lsoa.csv: Spatial column 'geography code' not found.\n",
      "combined_oa.csv: Spatial column 'geography code' not found.\n",
      "census2021-ts001-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts002-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts003-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts004-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts005-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts006-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts007a-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts008-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts011-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts015-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts016-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts017-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts018-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts019-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts020-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts021-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts023-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts025-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts026-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts027-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts029-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts030-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts032-lsoa.csv: inconsistency (Expected: 35672, Found: 1917)\n",
      "census2021-ts032-oa.csv: inconsistency (Expected: 35672, Found: 10275)\n",
      "census2021-ts033-lsoa.csv: inconsistency (Expected: 35672, Found: 1917)\n",
      "census2021-ts033-oa.csv: inconsistency (Expected: 35672, Found: 10275)\n",
      "census2021-ts034-lsoa.csv: inconsistency (Expected: 35672, Found: 1917)\n",
      "census2021-ts034-oa.csv: inconsistency (Expected: 35672, Found: 10275)\n",
      "census2021-ts035-lsoa.csv: inconsistency (Expected: 35672, Found: 1917)\n",
      "census2021-ts035-oa.csv: inconsistency (Expected: 35672, Found: 10275)\n",
      "census2021-ts036-lsoa.csv: inconsistency (Expected: 35672, Found: 1917)\n",
      "census2021-ts036-oa.csv: inconsistency (Expected: 35672, Found: 10275)\n",
      "census2021-ts037-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts038-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts039-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts040-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts041-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts044-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts045-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts046-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts050-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts051-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts052-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts053-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts054-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts055-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts056-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts058-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts059-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts061-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts062-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts063-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts065-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts066-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts067-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts068-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n",
      "census2021-ts075-oa.csv: inconsistency (Expected: 35672, Found: 188880)\n"
     ]
    }
   ],
   "source": [
    "def check_consistency(folder_path, feature):\n",
    "    \"\"\"\n",
    "    Check consistency for all CSV files in the given folder.\n",
    "\n",
    "    :param folder_path: Path to the folder containing CSV files.\n",
    "    :param feature: Name of the column to check.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    inconsistencies = []\n",
    "    rlt = {}\n",
    "\n",
    "    # Iterate through all files in the folder\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            try:\n",
    "                # Read the CSV file\n",
    "                df = pd.read_csv(file_path)\n",
    "\n",
    "                # Check if the spatial column exists\n",
    "                if feature in df.columns:\n",
    "                    # Get unique values in the spatial column\n",
    "                    unique_values = df[feature].unique()\n",
    "\n",
    "                    # Store the count of unique values for each file\n",
    "                    rlt[file] = len(unique_values)\n",
    "                else:\n",
    "                    inconsistencies.append(f\"{file}: Spatial column '{feature}' not found.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                inconsistencies.append(f\"{file}: Error reading file - {e}\")\n",
    "\n",
    "    # Compare resolutions across files\n",
    "    if len(rlt) > 1:\n",
    "        ref_ = next(iter(rlt.values()))  # Reference resolution from the first file\n",
    "        for file, res in rlt.items():\n",
    "            if res != ref_:\n",
    "                inconsistencies.append(f\"{file}: inconsistency (Expected: {ref_}, Found: {res})\")\n",
    "\n",
    "    if inconsistencies:\n",
    "        print(\"Inconsistencies found:\")\n",
    "        for issue in inconsistencies:\n",
    "            print(issue)\n",
    "    else:\n",
    "        print(\"All files are consistent.\")\n",
    "\n",
    "# Example usage\n",
    "check_consistency(folder_path=extract_to_folder, feature='geography code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
